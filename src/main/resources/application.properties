server.port=8080
server.address=0.0.0.0
# OpenAI Configuration
openai.api.key=
openai.model.name=gpt-4o-mini

# MCP Server Configuration
mcp.server.url=http://localhost:8080/mcp

# MCP Orchestrator Configuration
mcp.orchestrator.maxIterations=10

# OpenTelemetry Configuration
otel.exporter.otlp.endpoint=http://localhost:4317
otel.service.name=mcp-kyb-langchain-service
otel.service.version=1.0.0
otel.traces.exporter=otlp
otel.metrics.exporter=none
otel.logs.exporter=none

# Spring Boot Actuator Configuration
management.endpoints.web.exposure.include=health,info,metrics,prometheus,traces,llmStats
management.endpoint.health.show-details=always
management.metrics.export.prometheus.enabled=true
management.tracing.sampling.probability=1.0

# LLM Monitoring Configuration
llm.monitoring.enabled=true
llm.monitoring.log.prompts=true
llm.monitoring.log.responses=true
llm.monitoring.cost.alert.threshold=10.0

# LangSmith Configuration
langsmith.api.key=
langsmith.project.name=mcp-kyb-langchain
langsmith.enabled=true

# Logging Configuration
logging.level.com.mcpkyb=DEBUG
logging.level.io.opentelemetry=INFO
logging.level.com.mcpkyb.service.LLMMonitoringService=INFO
logging.pattern.level=%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]